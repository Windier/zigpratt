// const binding_power = enum {
//     Mul,
//     Div,
//     Add,
//     Sub,
// };

// pub fn Parser(tokens: TokenStream) void {
//   print("--Parser--\n", .{});
//   for (tokens.items) |t| {
//     print("[{s}] \n", .{@tagName(t.type)});
//   }
// }

// const Expression = union(enum) {
// 	Number: f64,
// 	Variable: []const u8,
// 	Unary: struct {
// 			op: TokenType,
// 			right: *Expression,
// 	},
// 	Binary: struct {
// 			left: *Expression,
// 			op: TokenType,
// 			right: *Expression,
// 	},
// 	pub fn deinit(self: *Expression, allocator: std.mem.Allocator) void {
// 		switch (self.*) {
// 			.Unary => |u| u.right.deinit(allocator),
// 			.Binary => |b| {
// 				b.left.deinit(allocator);
// 				b.right.deinit(allocator);
// 			},
// 			else => {},
// 		}
// 		allocator.destroy(self);
// 	}
// };

// const Expr = enum {
// 	Atom,
// 	Op,
// 	Invalid,
// 	Eof
// };

// const OpType = enum { infix };

// const Parser = struct {
// 	tokenizer: Tokenizer,
// 	previous: _Token,
// 	current: _Token,
// 	allocator: std.mem.Allocator,

// 	fn advance(self: *Parser) void {
// 		self.previous = self.current;
// 		self.current = self.tokenizer.next();
// 	}

// 	fn parse( tokenizer: &Tokenizer) Expr {
// 		// 1 + 2 * 3. This should start with an Atom 1
// 		let lhs = switch (tokenizer.next().tag) {
// 			TokenType.Integer => .Atom
// 			else => .Invalid
// 		};

// 		let op = switch (tokenizer.peek()) {
// 			TokenType.Plus =>
// 		}
// 	}
// };

// pub fn item(t: _Token) void {
// 	switch (t.tag) {
// 	}
// }


// fn printAST(expr: *const Expression, indent: u32) void {
//     const spaces = "                    ";
//     const prefix = spaces[0..@min(indent * 2, spaces.len)];

//     switch (expr.*) {
//         .Number => |n| print("{s}Number: {d}\n", .{prefix, n}),
//         .Variable => |v| print("{s}Variable: {s}\n", .{prefix, v}),
//         .Binary => |b| {
//             print("{s}Binary: {s}\n", .{prefix, @tagName(b.op)});
//             print("{s}├─ Left:\n", .{prefix});
//             printAST(b.left, indent + 1);
//             print("{s}└─ Right:\n", .{prefix});
//             printAST(b.right, indent + 1);
//         },
//         .Unary => |u| {
//             print("{s}Unary: {s}\n", .{prefix, @tagName(u.op)});
//             print("{s}└─ Operand:\n", .{prefix});
//             printAST(u.right, indent + 1);
//         },
//         .Grouping => |g| {
//             print("{s}Grouping:\n", .{prefix});
//             print("{s}└─ Expression:\n", .{prefix});
//             printAST(g.expression, indent + 1);
//         },
//     }
// }

// pub fn parseNumber(str: []const u8) TokenType {
//     var i: usize = 0;
//     var decimal_found: bool = false;
//     while (i < str.len) {
//         switch (str[i]) {
//             '0'...'1' => i += 1,
//             '.' => {
//                 if (decimal_found) {
//                     break;
//                 }
//                 decimal_found = true;
//                 i += 1;
//             },
//         }
//     }
// }


// pub fn Lexer(expr: []const u8) !TokenStream {
//   var token_stream = TokenStream.init(Allocator);
//   var pos: u64 = 0;
//   while (pos < expr.len) {
//     try token_stream.append(switch (expr[pos]) {
//       '+' => Token{ .type = .Plus },
//       '-' => Token{ .type = .Minus },
//       '*' => Token{ .type = .Asterisk },
//       '/' => Token{ .type = .Slash },
//       '0'...'9' => Token{ .type = .Number, .value = try std.fmt.parseInt(i64, expr[pos .. pos + 1], 10) },
//       else => .{ .type = .Eof },
//     });
//     pos += 1;
//   }

//   return token_stream;
// }


// const Expression = union(enum){
// 	Number: f64,
// 	Variable: []const u8,
// 	BinaryOperation: struct {
// 		op: TokenType,
// 		lhs: *Expression,
// 		rhs: *Expression,
// 	},
// 	Collection: struct {
// 		type: TokenType,
// 		elements: usize,
// 		children: [*]Expression
// 	}
// };